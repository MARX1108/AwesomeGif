{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "involved-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import tensorflow_hub as hub \n",
    "from tensorflow.keras import layers \n",
    "import bert \n",
    "import re \n",
    "# re — Regular expression operations\n",
    "import math\n",
    "import csv\n",
    "import pandas as pd                     \n",
    "import cv2 as cv \n",
    "from PIL import Image\n",
    "from tensorflow.keras import losses\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efficient-greensboro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125782, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/zimingfang/Desktop/Animated GIFs/AwesomeGif/tgif-v1.0.tsv\", sep='\\t')\n",
    "data.isnull().values.any()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "composed-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "positive-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "gif_links = list(data.y.values)\n",
    "raw_tweets = list(data.x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "instrumental-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gif_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "challenging-accommodation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-cliff",
   "metadata": {},
   "source": [
    "# Tweet Pre-Process "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-catch",
   "metadata": {},
   "source": [
    "## Remove Special Char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "severe-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition for function for removing html tags \n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "roman-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition for function for remove any punctuations and special characters\n",
    "def preprocess_text(raw_tweaet):\n",
    "    # Removing html tags\n",
    "    tweet = remove_tags(raw_tweaet)\n",
    "    # Removing html tags\n",
    "    tweet = re.sub('[^a-zA-Z]', '', tweet)\n",
    "    # Removing html tags\n",
    "    tweet = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', tweet)\n",
    "    # Removing multiple spaces\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "scheduled-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the preprocess_text function to clean tweets list \n",
    "tweets = [] \n",
    "for tweet in raw_tweets[:10]:\n",
    "    tweets.append(preprocess_text(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-panama",
   "metadata": {},
   "source": [
    "## Tokenizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "editorial-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer \n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\",\n",
    "                            trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "# .numpy(): converts a tensor object into an numpy.ndarray\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "modular-imagination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for function for convert tweet to ids \n",
    "def tokenize_tweets(text_tweets):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "difficult-proportion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the tokenize_tweets on tweets \n",
    "tokenized_tweets = [tokenize_tweets(tweet) for tweet in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-vector",
   "metadata": {},
   "source": [
    "# GIF Pre-Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "norman-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# Requests is an elegant and simple HTTP library for Python\n",
    "import os \n",
    "# os — Miscellaneous operating system interfaces¶\n",
    "os.chdir('/Users/zimingfang/Desktop/Animated GIFs/AwesomeGif/gifs')\n",
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "reported-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gif_downloader(image_urls, status=[], filenames = []):\n",
    "    \n",
    "    for index, img in enumerate(image_urls):\n",
    "        # We can split the file based upon / and extract the last split within the python list below:\n",
    "        file_name = img.split('/')[-1]\n",
    "        #print(\"fThis is the file name: {file_name}\")\n",
    "        filenames.append(file_name) \n",
    "        # Now let's send a request to the image URL:\n",
    "        r = requests.get(img, stream=True)\n",
    "        # We can check that the status code is 200 before doing anything else:\n",
    "        if r.status_code == 200:\n",
    "            # This command below will allow us to write the data to a file as binary:\n",
    "            with open(file_name, 'wb') as f:\n",
    "                for chunk in r:\n",
    "                    f.write(chunk)\n",
    "            status.append(True)\n",
    "        else:\n",
    "            # We will write all of the images back to the broken_images list:\n",
    "            status.append(False)\n",
    "    return filenames, status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "frequent-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_gif(image_path, sess):\n",
    "#     image = tf.io.read_file(image_file)\n",
    "#     image = tf.io.decode_gif(image)\n",
    "#     return sess.run(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "subjective-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "download_status = []\n",
    "filenames = []\n",
    "filenames, downlod_status = gif_downloader(gif_links[:10], status=download_status)\n",
    "# if any gif was not downloaded successfully \n",
    "print(any(status == False for status in download_status))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "terminal-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "creative-stake",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_contrast(path_to_gif):\n",
    "    gif_contrast = []\n",
    "    capture = cv.VideoCapture(path_to_gif)\n",
    "    pos_frame = capture.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "\n",
    "    while True: \n",
    "        isTrue, frame = capture.read()\n",
    "        img_grey = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        gif_contrast.append(img_grey.std())\n",
    "        if capture.get(cv2.CAP_PROP_POS_FRAMES) == capture.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "            # If the number of captured frames is equal to the total number of frames,\n",
    "            # we stop\n",
    "            break\n",
    "    return sum(gif_contrast) / len(gif_contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "military-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In GIF files, each frame has its own duration. So there is no general fps for a GIF file. \n",
    "contrast = []\n",
    "for gif_file_path in filenames[:10]: \n",
    "#     cap=cv2.VideoCapture(\"gif_file_path\")\n",
    "#     fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "#     gif_obj = Image.open(gif_file_path)\n",
    "    contrast.append(get_avg_contrast(gif_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "rural-probe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[68.42556184690109,\n",
       " 58.05193036668147,\n",
       " 63.387818026825364,\n",
       " 50.30206960661047,\n",
       " 62.45907835278932,\n",
       " 46.81373933565822,\n",
       " 81.60186270083663,\n",
       " 63.94421476526131,\n",
       " 50.60991991370668,\n",
       " 66.09166546706905]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-portfolio",
   "metadata": {},
   "source": [
    "# Prerparing Data For Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fatty-status",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenized_tweets\n",
    "y_train = contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "educated-administration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "therapeutic-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_with_len = [[tweet, y_train[i], len(tweet)]\n",
    "                 for i, tweet in enumerate(x_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "indonesian-finance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the data by tweet length \n",
    "tweets_with_len.sort(key=lambda x: x[2])\n",
    "#remove the tweet length attribute from dataset \n",
    "sorted_tweets_labels = [(tweet_lab[0], tweet_lab[1]) for tweet_lab in tweets_with_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "loaded-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_tweets_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "median-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the sorted dataset into a TensorFlow 2.0-compliant input dataset shape\n",
    "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_tweets_labels, output_types=(tf.int32, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "white-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10 \n",
    "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "whole-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_BATCHES = math.ceil(len(sorted_tweets_labels) / BATCH_SIZE)\n",
    "# TEST_BATCHES = TOTAL_BATCHES // 10\n",
    "TEST_BATCHES = 1\n",
    "batched_dataset.shuffle(TOTAL_BATCHES)\n",
    "test_data = batched_dataset.take(TEST_BATCHES)\n",
    "train_data = batched_dataset.skip(TEST_BATCHES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "alone-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(batched_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-turkish",
   "metadata": {},
   "source": [
    "# Creating the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "express-better",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_LENGTH = len(tokenizer.vocab)\n",
    "EMB_DIM = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cognitive-recruitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 200)         6104600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 6,104,801\n",
      "Trainable params: 6,104,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#GlobalAveragePooling1D layer returns a fixed-length output vector for each example by averaging over the sequence dimension.\n",
    "#allows the model to handle input of variable length, in the simplest way possible\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Embedding(VOCAB_LENGTH + 1, EMB_DIM),\n",
    "    layers.Dropout(0.2),    \n",
    "    layers.GlobalAveragePooling1D(), \n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='linear') #set activation to linear for regression\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "handmade-selling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expect x to be a non-empty array or dataset.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-6b83d9eaf2f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     epochs=epochs)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.4/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Expect x to be a non-empty array or dataset.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expect x to be a non-empty array or dataset."
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-buffer",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scattergl(y=history.history['loss'],\n",
    "                    name='Train'))\n",
    "\n",
    "fig.add_trace(go.Scattergl(y=history.history['val_loss'],\n",
    "                     name='Valid'))\n",
    "\n",
    "fig.update_layout(height=500, width=700,\n",
    "                  xaxis_title='Epoch',\n",
    "                  yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_data)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-resistance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
