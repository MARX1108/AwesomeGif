{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "equivalent-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import re \n",
    "import bert \n",
    "import tensorflow_hub as hub \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "molecular-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models \n",
    "avgBrightnessModel = keras.models.load_model('GIF models/avg_brightness_prediction_model.h5')\n",
    "entropyModel = keras.models.load_model('GIF models/entropy_prediction_model.h5')\n",
    "framerateModel = keras.models.load_model('GIF models/framerate_prediction_model.h5')\n",
    "avgSharpnessModel = keras.models.load_model('GIF models/avg_sharpness_prediction_model.h5')\n",
    "contrastModel = keras.models.load_model('GIF models/contrast_prediction_model.h5')\n",
    "durationModel = keras.models.load_model('GIF models/duration_prediction_model.h5')\n",
    "faceCountModel = keras.models.load_model('GIF models/face_count_prediction_model.h5')\n",
    "numberOfPixelsModel = keras.models.load_model('GIF models/number_of_pixels_prediction_model.h5')\n",
    "pixelNoiseModel = keras.models.load_model('GIF models/pixel_noise_prediction_model.h5')\n",
    "qualityModel = keras.models.load_model('GIF models/quality_prediction_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vital-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text \n",
    "# definition for function for removing html tags \n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "# definition for function for remove any punctuations and special characters\n",
    "def preprocess_text(raw_tweaet):\n",
    "    # Removing html tags\n",
    "    tweet = remove_tags(raw_tweaet)\n",
    "    # Removing html tags\n",
    "    tweet = re.sub('[^a-zA-Z]', '', tweet)\n",
    "    # Removing html tags\n",
    "    tweet = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', tweet)\n",
    "    # Removing multiple spaces\n",
    "    tweet = re.sub(r'\\s+', ' ', tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conceptual-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tokenizer \n",
    "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
    "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\", trainable=False)\n",
    "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
    "# .numpy(): converts a tensor object into an numpy.ndarray\n",
    "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
    "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)\n",
    "\n",
    "# Definition for function for convert tweet to ids \n",
    "def tokenize_tweets(text_tweets):\n",
    "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "traditional-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean, tokenized, and format the raw text \n",
    "def format_text(raw_text):\n",
    "    clean_text = preprocess_text(raw_text)\n",
    "    tokenized_text = tokenize_tweets(clean_text)\n",
    "    formatted_text = tf.ragged.constant([tokenized_text], dtype=tf.int32)\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "swiss-hungary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take in a processed text, output predicted GIF feature as a list \n",
    "def predict_GIF_features(formatted_input):\n",
    "    brightness = avgBrightnessModel.predict(formatted_input)[0][0]\n",
    "    entropy = entropyModel.predict(formatted_input)[0][0]\n",
    "    framerate = framerateModel.predict(formatted_input)[0][0]\n",
    "    avgSharpness = avgSharpnessModel.predict(formatted_input)[0][0]\n",
    "    contrast = contrastModel.predict(formatted_input)[0][0]\n",
    "    duration = durationModel.predict(formatted_input)[0][0]\n",
    "    faceCount = faceCountModel.predict(formatted_input)[0][0]\n",
    "    numberOfPixels = numberOfPixelsModel.predict(formatted_input)[0][0]\n",
    "    pixelNoise = pixelNoiseModel.predict(formatted_input)[0][0]\n",
    "    quality = qualityModel.predict(formatted_input)[0][0]\n",
    "    summary = {'Average_Brightness': brightness, \n",
    "               'Entropy': entropy, \n",
    "               'Framerate': framerate, \n",
    "               'Avg_Sharpness': avgSharpness, \n",
    "               'Contrast': contrast, \n",
    "               'Duration': duration, \n",
    "               'Face_Count': faceCount, \n",
    "               'Number_Of_Pixels': numberOfPixels, \n",
    "               'Pixel_Noise': pixelNoise, \n",
    "               'Quality': quality,}\n",
    "    return summary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "recovered-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration \n",
    "result = predict_GIF_features(format_text(\"Happy to meet you at last, Yully.\"))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dirty-plant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
